{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import model_params as params\n",
    "import utils.resnet_orig as resnet\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats(model, device, model_params):\n",
    "    print(tt.test(model, device, model_params.test_loader, min_conf=.101)[0])\n",
    "    df = ev.evaluate(model, device, model_params.data_name, model_params.loaders)\n",
    "    return df\n",
    "\n",
    "def evaluate(model_params, device, file_joint, file_base, file_gmm):\n",
    "    model_joint = torch.load('SavedModels/' + file_joint).to(device)\n",
    "\n",
    "    df_joint = show_stats(model_joint, device, model_params)\n",
    "    df_joint_base = show_stats(model_joint.base_model, device, model_params)\n",
    "\n",
    "    base_model = torch.load('SavedModels/base/' + file_base)\n",
    "    gmm = torch.load('SavedModels/GMM/' + file_gmm)\n",
    "\n",
    "    lam = model_joint.loglam\n",
    "    model = models.RobustModel(base_model, gmm, lam, dim=model_params.dim).to(device)\n",
    "\n",
    "    df_sep = show_stats(model, device, model_params)\n",
    "    df_sep_base = show_stats(model.base_model, device, model_params)\n",
    " \n",
    "    df1 = pd.concat([df_sep_base, df_sep], axis=1, keys=['Base', 'GMM'])\n",
    "    df2 = pd.concat([df_joint_base, df_joint], axis=1, keys=['Base', 'GMM'])\n",
    "    return df1, df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9951\n",
      "0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948\n",
      "0.9949\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &  FPR@95 &       MMC &     AUROC &  FPR@95 \\\\\n",
      "DataSet     &           &           &         &           &           &         \\\\\n",
      "\\midrule\n",
      "orig        &  0.991813 &         - &       - &  0.991729 &         - &       - \\\\\n",
      "FMNIST      &  0.655473 &  0.977823 &  0.1485 &  0.487139 &   0.98104 &  0.1278 \\\\\n",
      "EMNIST      &  0.805926 &  0.906156 &  0.3764 &  0.803764 &  0.903264 &  0.3754 \\\\\n",
      "GrayCIFAR10 &  0.397742 &  0.998202 &  0.0027 &  0.100134 &   0.99995 &       0 \\\\\n",
      "Noise       &  0.121303 &  0.999999 &       0 &  0.105445 &  0.999928 &       0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &      FPR@95 &       MMC &     AUROC &  FPR@95 \\\\\n",
      "DataSet     &           &           &             &           &           &         \\\\\n",
      "\\midrule\n",
      "orig        &  0.992110 &         - &           - &  0.992025 &         - &       - \\\\\n",
      "FMNIST      &  0.580610 &  0.985719 &      0.1205 &  0.414878 &    0.9885 &  0.1013 \\\\\n",
      "EMNIST      &  0.809260 &  0.904668 &      0.3861 &  0.807062 &  0.901833 &  0.3853 \\\\\n",
      "GrayCIFAR10 &  0.226676 &   0.99972 &           0 &  0.100194 &  0.999949 &       0 \\\\\n",
      "Noise       &  0.126766 &  0.999991 &  7.8125e-05 &  0.107926 &  0.999928 &       0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'MNIST'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCAMNIST_lam0.0_n100_lr0.001_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_MNIST_lr0.001_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_MNIST_n100_data_used60000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424\n",
      "0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1218\n",
      "0.1218\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet     &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig        &  0.971288 &         - &         - &  0.970874 &         - &         - \\\\\n",
      "MNIST       &  0.778298 &   0.91646 &    0.2989 &  0.778298 &  0.915989 &    0.2989 \\\\\n",
      "EMNIST      &  0.701693 &   0.93547 &    0.1973 &  0.701692 &  0.934992 &    0.1973 \\\\\n",
      "GrayCIFAR10 &  0.861510 &  0.818207 &    0.5213 &  0.861342 &  0.817707 &    0.5213 \\\\\n",
      "Noise       &  0.659809 &  0.940255 &  0.191953 &  0.652225 &  0.940252 &  0.193281 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &      AUROC &      FPR@95 &       MMC &      AUROC &      FPR@95 \\\\\n",
      "DataSet     &           &            &             &           &            &             \\\\\n",
      "\\midrule\n",
      "orig        &  0.580610 &          - &           - &  0.580436 &          - &           - \\\\\n",
      "MNIST       &  0.992110 &  0.0142813 &      0.9699 &  0.992111 &  0.0143148 &      0.9699 \\\\\n",
      "EMNIST      &  0.809260 &   0.235348 &      0.3861 &  0.809260 &   0.235258 &      0.3862 \\\\\n",
      "GrayCIFAR10 &  0.226676 &   0.915391 &           0 &  0.226538 &   0.915265 &           0 \\\\\n",
      "Noise       &  0.180323 &   0.953014 &  7.8125e-05 &  0.176931 &   0.955516 &  0.00015625 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'FMNIST'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCAFMNIST_lam0.0_n100_lr0.001_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_MNIST_lr0.001_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_FMNIST_n100_data_used60000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.9595113706207744\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.9595497848801475\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9690765212046711\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.9691917639827904\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.975878 &         - &         - &  0.975859 &         - &         - \\\\\n",
      "CIFAR10   &  0.726107 &    0.9309 &    0.2084 &  0.572675 &  0.949249 &    0.1526 \\\\\n",
      "CIFAR100  &  0.736866 &  0.924342 &    0.2259 &  0.541490 &  0.948574 &    0.1553 \\\\\n",
      "LSUN\\_CR   &  0.728132 &  0.924333 &  0.216667 &  0.161476 &     0.992 &      0.02 \\\\\n",
      "Imagenet- &  0.735721 &  0.927048 &    0.2261 &  0.212153 &  0.988216 &     0.038 \\\\\n",
      "Noise     &  0.685477 &  0.946663 &   0.14751 &  0.682895 &  0.946834 &  0.145953 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.983783 &         - &         - &  0.983695 &         - &         - \\\\\n",
      "CIFAR10   &  0.686065 &   0.95698 &    0.1753 &  0.532799 &   0.96649 &    0.1378 \\\\\n",
      "CIFAR100  &  0.680707 &  0.955538 &    0.1808 &  0.497773 &  0.967336 &    0.1325 \\\\\n",
      "LSUN\\_CR   &  0.667355 &    0.9665 &  0.193333 &  0.141988 &  0.997278 &      0.02 \\\\\n",
      "Imagenet- &  0.634311 &  0.962783 &     0.151 &  0.195740 &  0.991816 &    0.0317 \\\\\n",
      "Noise     &  0.644626 &  0.966522 &  0.137751 &  0.643458 &   0.96601 &  0.138051 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'SVHN'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCASVHN_lam0.0_n100_lr0.001_lrgmm1e-06_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_SVHN_lr0.01_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_SVHN_n100_data_used50000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.8881\n",
      "0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303\n",
      "0.9309\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.931302 &         - &         - &  0.930700 &         - &         - \\\\\n",
      "SVHN      &  0.756881 &  0.845316 &    0.1989 &  0.756884 &  0.844335 &    0.1989 \\\\\n",
      "CIFAR100  &  0.747215 &  0.830066 &    0.2409 &  0.744823 &  0.829108 &    0.2408 \\\\\n",
      "LSUN\\_CR   &  0.695819 &  0.860633 &  0.176667 &  0.682758 &    0.8652 &  0.166667 \\\\\n",
      "Imagenet- &  0.734040 &  0.837583 &    0.2269 &  0.674854 &  0.851392 &    0.2077 \\\\\n",
      "Noise     &  0.762270 &  0.837077 &  0.215625 &  0.762318 &  0.834172 &  0.217734 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.962103 &         - &         - &  0.961502 &         - &         - \\\\\n",
      "SVHN      &  0.746868 &  0.915768 &    0.1769 &  0.746867 &  0.914832 &    0.1769 \\\\\n",
      "CIFAR100  &  0.780495 &  0.872262 &    0.3078 &  0.777783 &  0.870928 &    0.3068 \\\\\n",
      "LSUN\\_CR   &  0.723096 &  0.913422 &  0.163333 &  0.710133 &  0.916461 &  0.156667 \\\\\n",
      "Imagenet- &  0.776052 &  0.870232 &    0.3091 &  0.713777 &  0.880671 &    0.2804 \\\\\n",
      "Noise     &  0.750426 &  0.909976 &  0.170703 &  0.751644 &  0.908653 &  0.168906 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'CIFAR10'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCACIFAR10_lam0.0_n100_lr0.001_lrgmm1e-06_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_CIFAR10_lr0.01_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_CIFAR10_n100_data_used50000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
