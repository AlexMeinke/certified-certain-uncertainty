import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from importlib import reload

import utils.models as models
import utils.plotting as plotting
import utils.dataloaders as dl
import utils.traintest as tt
import utils.adversarial as adv
import utils.eval as ev

import argparse

parser = argparse.ArgumentParser(description='Define hyperparameters.')
parser.add_argument('--gpu', type=int, default=2, help='GPU index.')
parser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate.')


hps = parser.parse_args()

device = torch.device('cuda:' + str(hps.gpu))

base_model = models.LeNetMadry().to(device)


base_model = models.LeNetMadry().to(device)
gmm = torch.load('SavedModels/MNIST_gmm.pth')
gmm_model = models.RobustModel(base_model, gmm, -2.).to(device)
gmm_model.loglam.requires_grad = False


lr = hps.lr

optimizer = optim.Adam([gmm_model.mm.parameters(), gmm_model.base_model.parameters()], lr=lr, weight_decay=5e-4)
for epoch in range(100):
    if epoch+1 in [50,75,90]:
        for group in optimizer.param_groups:
            group['lr'] *= .1
    tt.train_ACET(base_model, device, dl.MNIST_train_loader, dl.Noise_loader, optimizer, epoch)
torch.save(base_model, 'SavedModels/MNIST_base_model.pth')

base_df = ev.evaluate_MNIST(base_model, device)
base_df.to_csv('results/base_model')