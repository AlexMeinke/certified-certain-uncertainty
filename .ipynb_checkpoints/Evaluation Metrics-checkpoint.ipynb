{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import models\n",
    "import plotting\n",
    "import utils.dataloaders as dl\n",
    "import traintest as tt\n",
    "import adversarial as adv\n",
    "import utils.preproc as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = torch.load('SavedModels/base_model.pth').to(device)\n",
    "gmm_model = torch.load('SavedModels/gmm_model.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(model, device, in_loader, out_loader, thresholds=torch.linspace(.1, 1., 1000).to(device)):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        conf_in = []\n",
    "        conf_out = []\n",
    "        count = 0.\n",
    "        for ((batch_idx, (data_in, _)), (_, (data_out, _))) in zip(enumerate(in_loader),enumerate(out_loader)):\n",
    "            count += 1\n",
    "            data_in = data_in.to(device)\n",
    "            data_out = data_out.to(device)\n",
    "\n",
    "            output_in = model(data_in).max(1)[0].exp()\n",
    "            output_out = model(data_out).max(1)[0].exp()\n",
    "\n",
    "            conf_in.append(output_in)\n",
    "            conf_out.append(output_out)\n",
    "        conf_in = torch.cat(conf_in)\n",
    "        conf_out = torch.cat(conf_out)\n",
    "        \n",
    "        tp = (conf_in[:,None] > thresholds[None,:]).sum(0).float()/(count*in_loader.batch_size)\n",
    "        fp = (conf_out[:,None] > thresholds[None,:]).sum(0).float()/(count*out_loader.batch_size)\n",
    "        \n",
    "        mmc = conf_out.mean().item()\n",
    "        auroc = -np.trapz(tp.cpu().numpy(), x=fp.cpu().numpy())\n",
    "        fp95 = ((conf_out > 0.95).sum().float()/(count*out_loader.batch_size)).item()\n",
    "        return mmc, auroc, fp95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, device, base_loader, loaders):\n",
    "    metrics = []\n",
    "    mmc, _, _ = test_metrics(model, device, base_loader, base_loader)\n",
    "    metrics.append(['MNIST', mmc, '-', '-'])\n",
    "    for (name, data_loader) in loaders:\n",
    "        mmc, auroc, fp95 = test_metrics(model, device, base_loader, data_loader)\n",
    "        metrics.append([name, mmc, auroc, fp95])\n",
    "    df = pd.DataFrame(metrics, columns = ['DataSet', 'MMC', 'AUROC', 'FPR@95'])\n",
    "    return df.set_index('DataSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdversarialNoiseLoader = adv.create_adv_noise_loader(base_model, dl.Noise_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdversarialSampleLoader = adv.create_adv_noise_loader(base_model, dl.MNIST_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = (\n",
    "[('FMNIST', dl.FMNIST_test_loader), \n",
    " ('EMNIST', dl.EMNIST_test_loader),\n",
    " ('GrayCIFAR10', dl.GrayCIFAR10_test_loader),\n",
    " ('Noise', dl.Noise_loader),\n",
    " ('Adv. Noise', AdversarialNoiseLoader ),\n",
    " ('Adv. Sample', AdversarialSampleLoader)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = evaluate_model(base_model, device, dl.MNIST_test_loader, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>FPR@95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataSet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MNIST</th>\n",
       "      <td>0.992019</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMNIST</th>\n",
       "      <td>0.692214</td>\n",
       "      <td>0.983835</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMNIST</th>\n",
       "      <td>0.853812</td>\n",
       "      <td>0.868063</td>\n",
       "      <td>0.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrayCIFAR10</th>\n",
       "      <td>0.632773</td>\n",
       "      <td>0.989706</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noise</th>\n",
       "      <td>0.385521</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adv. Noise</th>\n",
       "      <td>0.996400</td>\n",
       "      <td>0.47135</td>\n",
       "      <td>0.9884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adv. Sample</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MMC     AUROC  FPR@95\n",
       "DataSet                                \n",
       "MNIST        0.992019         -       -\n",
       "FMNIST       0.692214  0.983835   0.111\n",
       "EMNIST       0.853812  0.868063  0.4885\n",
       "GrayCIFAR10  0.632773  0.989706  0.0572\n",
       "Noise        0.385521  0.999365       0\n",
       "Adv. Noise   0.996400   0.47135  0.9884\n",
       "Adv. Sample  0.999999    0.4203       1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM_AdversarialNoiseLoader = adv.create_adv_noise_loader(gmm_model, dl.Noise_loader, device)\n",
    "GMM_AdversarialSampleLoader = adv.create_adv_noise_loader(gmm_model, dl.MNIST_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM_loaders = (\n",
    "[('FMNIST', dl.FMNIST_test_loader), \n",
    " ('EMNIST', dl.EMNIST_test_loader),\n",
    " ('GrayCIFAR10', dl.GrayCIFAR10_test_loader),\n",
    " ('Noise', dl.Noise_loader),\n",
    " ('Adv. Noise', GMM_AdversarialNoiseLoader ),\n",
    " ('Adv. Sample', GMM_AdversarialSampleLoader)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_df = evaluate_model(gmm_model, device, dl.MNIST_test_loader, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.merge(gmm_df, right_index=1, left_index=1, suffixes=(\"_plain\", \"_gmm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
