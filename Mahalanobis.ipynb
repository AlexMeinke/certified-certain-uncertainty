{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from importlib import reload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import mixture, preprocessing, datasets\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import utils.mahalanobis as resnet\n",
    "\n",
    "import utils.dataloaders as dl\n",
    "import tqdm\n",
    "\n",
    "import model_params as params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "\n",
    "pre_trained_net = '../deep_Mahalanobis_detector/pre_trained/resnet_cifar10.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet.ResNet34(num_c=10)\n",
    "model.load_state_dict(torch.load(pre_trained_net, map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_loader = dl.CIFAR10(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_statistics(model, device, loader):\n",
    "    model.eval()\n",
    "    classes = 10\n",
    "    class_num = ((torch.tensor(loader.dataset.targets)[:,None]\n",
    "                  == torch.arange(10)[None,:]).sum(0).float())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        data = enumerate(loader).__next__()[1][0].to(device)\n",
    "        _, act = model.penultimate_forward(data)\n",
    "        act = [act]\n",
    "\n",
    "        dims = [a[0].view(-1).shape[0] for a in act]\n",
    "        mean = [torch.zeros(classes, d) for d in dims]\n",
    "        cov = [torch.zeros(d, d) for d in dims]\n",
    "\n",
    "        for data, label in loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            label = torch.zeros(label.shape[0], classes, \n",
    "                                device=device).scatter_(1, label[:,None], 1)\n",
    "\n",
    "            _, act = model.penultimate_forward(data)\n",
    "\n",
    "            for i, layer_act in enumerate([act]):\n",
    "                mean[i] += (layer_act.view(layer_act.shape[0], -1)[:,None,:]\n",
    "                            * label[:,:,None]).sum(0).cpu()\n",
    "        for i, _ in enumerate(mean):\n",
    "            mean[i] = mean[i] / class_num[:,None]\n",
    "        \n",
    "        for idx, (data, label) in enumerate(loader):\n",
    "            print(idx)\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            _, act = model.penultimate_forward(data)\n",
    "\n",
    "            for i, layer_act in enumerate([act]):\n",
    "                diff = (layer_act.view(layer_act.shape[0], -1).cpu() - mean[i][label])\n",
    "                cov[i] += (diff[:,:,None] * diff[:,None,:]).sum(0)\n",
    "                \n",
    "        for i, _ in enumerate(cov):\n",
    "            cov[i] = cov[i] / class_num.sum()\n",
    "        return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "mean, cov = compute_layer_statistics(model, device, in_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.mahalanobis' from '/home/alexm/project/notebooks/gmm-robust/utils/mahalanobis.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "odin = resnet.ModelODIN(model, 0.0004, mean[0], cov[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "odin, T, eps = resnet.grid_search_variables(model, model_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(in_loader))[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = params.params_dict['CIFAR10']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -31.0850,  -16.9696,  -16.4578,   -5.0314,  -18.1555,  -13.7981,\n",
       "          -21.4746,  -32.3519,  -22.7567,  -35.2783],\n",
       "        [ -33.1156,  -33.4961,  -41.5007,  -37.3031,  -43.9631,  -40.6855,\n",
       "          -42.6369,  -48.6889,   -7.2270,  -45.9021],\n",
       "        [ -68.2058,  -18.0579,  -70.7925,  -46.7569,  -72.9105,  -65.1016,\n",
       "          -75.1489,  -89.0507,  -57.3310,  -38.0976],\n",
       "        [  -9.6770,  -36.2028,  -50.5123,  -47.4465,  -58.2253,  -30.5233,\n",
       "          -51.2334,  -58.9126,  -25.3214,  -51.5401],\n",
       "        [ -84.0681,  -74.0115,  -56.7595,  -73.8843,  -67.7269,  -65.8684,\n",
       "          -23.7110,  -91.7916,  -76.1788,  -73.0908],\n",
       "        [ -29.4991,  -30.7605,  -23.4460,   -9.4966,  -27.3751,  -16.1693,\n",
       "          -29.0386,  -10.4514,  -38.9258,  -26.3791],\n",
       "        [ -66.9303,  -12.5126,  -64.9145,  -59.6089,  -58.5747,  -55.9651,\n",
       "          -63.9920,  -84.1561,  -62.8276,  -54.6009],\n",
       "        [ -32.4723,  -44.2659,  -15.4199,  -26.4733,   -6.4765,  -24.8320,\n",
       "          -26.9652,  -34.0775,  -37.6495,  -47.5787],\n",
       "        [ -12.9234,  -23.3866,  -13.2954,   -1.6309,  -12.4744,   -7.2663,\n",
       "          -20.4847,  -23.2728,  -23.8351,  -28.6496],\n",
       "        [ -74.0738,  -28.5032,  -54.6754,  -54.0349,  -54.9043,  -55.3413,\n",
       "          -48.8471,  -68.2818,  -59.0310,  -22.6944],\n",
       "        [ -19.5853,  -83.7821,  -60.0847,  -63.6188,  -69.4065,  -55.8157,\n",
       "          -69.4509,  -78.5793,  -67.9976,  -65.1595],\n",
       "        [ -74.6437,  -68.9712,  -83.7636,  -60.1975,  -74.0077,  -69.8510,\n",
       "          -70.5552,  -84.3874,  -78.6043,  -18.9185],\n",
       "        [ -46.9269,  -40.5847,  -32.0513,  -25.0410,  -18.8500,  -12.2648,\n",
       "          -29.3378,  -20.8792,  -35.5966,  -44.9197],\n",
       "        [ -53.9589,  -69.1305,  -52.6037,  -35.4530,  -45.8248,  -42.4557,\n",
       "          -48.4655,   -5.8898,  -57.0919,  -52.4213],\n",
       "        [ -74.4199,  -65.4172,  -72.5666,  -63.2091,  -63.0376,  -56.9187,\n",
       "          -60.8433,  -82.3001,  -84.0956,  -16.3302],\n",
       "        [ -30.2302,  -32.7175,  -51.2830,  -52.6555,  -47.5070,  -50.2100,\n",
       "          -47.2445,  -65.5751,   -9.8492,  -46.0583],\n",
       "        [ -46.5869,  -65.5213,  -45.6754,  -33.9898,  -42.9043,  -14.6970,\n",
       "          -41.9940,  -35.8055,  -52.5297,  -52.3573],\n",
       "        [ -75.9736,  -80.0829,  -63.1927,  -47.0188,  -56.3687,  -56.8522,\n",
       "          -62.2767,  -11.1137,  -77.9512,  -68.1039],\n",
       "        [ -25.2286,  -32.7713,  -39.5599,  -27.2274,  -41.6550,  -26.2043,\n",
       "          -33.1655,  -46.9728,   -3.9670,  -34.1921],\n",
       "        [ -69.2342,  -72.3293,  -63.8565,  -66.4006,  -57.4621,  -67.9184,\n",
       "          -19.5434,  -82.0159,  -79.9203,  -70.1691],\n",
       "        [ -56.3709,  -73.6097,  -56.2115,  -51.6672,  -52.7365,  -29.6301,\n",
       "          -54.4609,   -7.6717,  -65.4424,  -56.5628],\n",
       "        [ -17.8259,  -43.1525,  -12.6624,  -19.8092,  -18.4809,  -27.6417,\n",
       "          -10.9909,  -44.0521,  -35.8581,  -39.5893],\n",
       "        [ -40.4727,  -45.8378,  -42.3089,  -46.9434,   -8.6736,  -39.4100,\n",
       "          -29.4190,  -50.7530,  -45.3701,  -42.9876],\n",
       "        [ -68.8294,  -65.8124,  -67.8008,  -72.8043,  -73.4608,  -58.7480,\n",
       "          -69.3239,  -82.0902,  -79.4570,  -20.3403],\n",
       "        [ -38.0643,  -36.2198,  -16.4751,   -6.6474,  -12.8586,   -6.9426,\n",
       "          -26.5546,  -20.8589,  -24.8825,  -38.7672],\n",
       "        [ -50.0764,  -76.2628,  -11.7537,  -42.6765,  -44.4589,  -40.6335,\n",
       "          -43.9272,  -60.4114,  -48.2857,  -57.9737],\n",
       "        [ -26.4365,  -51.2314,  -27.4075,  -39.8349,   -7.0501,  -27.8212,\n",
       "          -27.3848,  -39.6814,  -49.2640,  -38.9955],\n",
       "        [ -20.6905,  -65.3329,  -48.5900,  -41.9518,  -41.9390,  -57.0991,\n",
       "          -57.9754,  -57.4619,  -59.7456,  -49.4112],\n",
       "        [ -53.7179,  -20.3474,  -62.4084,  -46.6530,  -72.1245,  -50.1247,\n",
       "          -64.2636,  -61.3777,  -46.1012,  -21.0902],\n",
       "        [ -76.7529,  -75.5487,  -69.5122,  -75.2031,  -69.0201,  -69.9872,\n",
       "          -26.3275,  -81.5259,  -74.0482,  -71.8393],\n",
       "        [ -24.1985,  -14.1953,  -11.1851,   -2.5892,  -21.3739,  -13.8885,\n",
       "          -16.0158,  -30.9592,  -20.9253,  -19.9218],\n",
       "        [ -53.1990,  -46.5169,  -48.2916,  -43.9676,  -34.3038,  -18.7240,\n",
       "          -42.6126,  -41.4838,  -51.9752,  -33.9188],\n",
       "        [ -53.2973,  -69.2823,  -33.1077,  -45.3663,   -9.3747,  -49.4928,\n",
       "          -34.4734,  -48.2759,  -55.4581,  -60.1708],\n",
       "        [ -28.8700,  -13.2123,  -34.1187,  -23.5978,  -37.1219,  -13.9725,\n",
       "          -35.6459,  -37.3248,  -27.9969,  -39.2651],\n",
       "        [ -57.9910,  -57.3064,  -64.6203,  -61.6255,  -68.2652,  -64.7656,\n",
       "          -59.7947,  -82.8224,  -63.6175,  -14.8594],\n",
       "        [ -51.2651,  -54.7666,  -14.9094,  -34.9299,  -48.1585,  -36.9871,\n",
       "          -43.5370,  -56.2261,  -43.3304,  -54.3053],\n",
       "        [ -57.2019,  -50.3289,  -50.5097,  -32.7157,  -13.4020,  -50.1076,\n",
       "          -34.6646,  -53.4645,  -67.0894,  -52.2246],\n",
       "        [ -54.2711,  -22.6827,  -73.6662,  -52.8600,  -61.6089,  -45.1807,\n",
       "          -77.9696,  -87.9259,  -53.6427,  -22.8140],\n",
       "        [ -70.3187,  -65.3336,  -64.6652,  -65.9205,  -69.4572,  -66.0056,\n",
       "          -70.9104,  -88.4100,  -65.0257,  -16.3981],\n",
       "        [ -49.9069,  -44.8287,  -45.1050,  -38.4599,  -37.5750,  -20.1806,\n",
       "          -44.2461,  -47.6521,  -48.1034,  -48.6988],\n",
       "        [ -39.2216,  -48.3292,  -30.7056,  -30.4907,   -7.6707,  -27.6470,\n",
       "          -34.3133,  -43.8411,  -41.3738,  -51.9824],\n",
       "        [ -70.4273,  -71.8670,  -42.6465,  -61.3277,  -55.7006,  -57.3779,\n",
       "          -18.5868,  -79.1234,  -59.8995,  -74.5484],\n",
       "        [ -37.9107,  -55.0485,   -5.5593,  -21.5047,  -31.2239,  -28.3199,\n",
       "          -32.1948,  -46.9408,  -38.6845,  -34.6778],\n",
       "        [ -84.9696,  -53.1559,  -55.4191,  -62.8222,  -66.8909,  -59.0447,\n",
       "          -24.3009,  -78.8128,  -67.5532,  -81.0095],\n",
       "        [ -11.1200,  -53.8677,  -46.1234,  -42.3038,  -51.2175,  -72.1735,\n",
       "          -64.1717,  -64.1579,  -48.7602,  -52.5849],\n",
       "        [ -68.3684,  -61.9855,  -74.5701,  -57.8968,  -71.6010,  -72.5315,\n",
       "          -78.8542,  -91.0041,  -77.6319,  -18.4807],\n",
       "        [ -47.5167,  -62.4428,  -45.6707,  -39.9475,  -43.8871,  -24.0885,\n",
       "          -37.6316,  -49.4084,  -58.4281,  -65.1006],\n",
       "        [ -22.7114,  -40.0778,  -27.6599,  -23.6316,  -23.7209,  -31.0793,\n",
       "          -24.0221,  -22.4899,   -8.6846,  -16.3694],\n",
       "        [ -82.3002,  -83.1437,  -72.6829,  -69.6880,  -62.5886,  -68.2118,\n",
       "          -68.1667,  -12.4680,  -81.6674,  -92.1171],\n",
       "        [ -33.2255,  -46.2327,   -9.0025,  -33.2269,  -22.7356,  -33.4251,\n",
       "          -30.3997,  -50.1894,  -47.2992,  -49.3184],\n",
       "        [ -34.2680,  -58.8075,  -35.5744,  -43.2646,  -50.0590,  -44.7720,\n",
       "          -37.1762,  -50.5024,  -47.3119,  -16.1499],\n",
       "        [ -17.5477,  -33.4247,  -27.2914,  -28.2712,  -19.4654,  -33.1025,\n",
       "          -30.2716,  -44.6270,   -7.9677,  -32.1861],\n",
       "        [ -27.6385,  -54.7280,  -19.9109,  -17.8969,  -32.0437,  -22.3900,\n",
       "          -33.5424,  -11.1302,  -42.6891,  -29.1195],\n",
       "        [ -45.6104,  -76.0134,  -37.6913,  -43.6820,  -38.8976,  -19.6749,\n",
       "          -43.9332,  -35.5177,  -56.7057,  -59.3107],\n",
       "        [ -30.5097,  -35.2584,  -39.0747,  -41.3734,  -56.6591,  -44.8028,\n",
       "          -48.3735,  -58.4374,   -6.3926,  -39.3889],\n",
       "        [ -23.5753,  -34.1026,  -27.2345,  -34.3415,  -43.3862,  -40.7730,\n",
       "          -38.1178,  -53.9909,   -5.0672,  -35.1567],\n",
       "        [ -75.6865,  -90.2709,  -79.3129,  -56.7015,  -63.7492,  -60.9562,\n",
       "          -75.4117,  -14.9451,  -82.2704,  -73.8005],\n",
       "        [ -16.7402,  -19.0842,   -4.6043,   -4.8787,   -6.7687,   -4.5609,\n",
       "          -11.8219,  -20.8280,  -19.1052,  -15.2798],\n",
       "        [ -33.5429,  -52.8206,  -36.7705,  -31.6267,  -32.8791,  -12.7850,\n",
       "          -41.4580,  -38.0624,  -37.6716,  -45.1873],\n",
       "        [ -55.9664,  -65.4877,  -56.2770,  -50.9790,  -54.3170,  -21.3010,\n",
       "          -48.0173,  -50.4810,  -64.3689,  -54.9475],\n",
       "        [ -86.1871,  -84.5224,  -65.4259,  -60.1169,  -75.1140,  -57.7079,\n",
       "          -80.5696,  -12.1874,  -77.5071,  -84.9714],\n",
       "        [ -23.7055,  -32.0291,   -9.7395,   -9.3380,  -13.9727,   -3.1471,\n",
       "          -23.6537,  -23.9812,  -29.3937,  -25.0372],\n",
       "        [ -20.6465,  -36.5510,   -9.7104,  -11.1926,   -9.2772,  -15.4937,\n",
       "           -2.9963,  -30.9422,  -22.6824,  -19.8810],\n",
       "        [ -18.2040,  -21.7505,  -12.4189,   -2.1858,  -16.3990,   -9.1918,\n",
       "          -17.8640,  -23.1919,  -17.6827,  -14.0766],\n",
       "        [ -22.7197,  -23.1217,  -13.8858,   -3.0027,  -20.1153,  -13.7316,\n",
       "          -22.2145,  -27.9716,  -26.4759,  -22.8405],\n",
       "        [ -72.9549,  -92.6416,  -24.9035,  -55.0089,  -60.6107,  -62.3249,\n",
       "          -59.2993,  -88.1430,  -80.4817,  -74.2515],\n",
       "        [ -92.1266,  -14.6732,  -88.6486,  -63.6821,  -78.5627,  -92.3199,\n",
       "          -76.6657,  -99.1498,  -65.8467,  -84.0868],\n",
       "        [ -52.7983,  -74.4131,  -12.3216,  -43.4514,  -40.7203,  -41.1864,\n",
       "          -46.8611,  -66.5116,  -58.6294,  -63.6344],\n",
       "        [ -55.0562,  -44.7824,  -49.5066,  -40.0369,  -62.2147,  -38.5774,\n",
       "          -49.7517,  -64.7382,  -58.5772,  -11.7297],\n",
       "        [ -44.0173,  -66.4784,  -58.3309,  -44.0667,  -48.7718,  -41.0980,\n",
       "          -46.4910,   -8.2900,  -62.4892,  -58.4150],\n",
       "        [ -40.0580,  -53.6113,  -14.3405,  -34.5463,  -41.9011,  -28.9582,\n",
       "          -41.7304,  -50.4289,  -45.3180,  -50.3057],\n",
       "        [ -67.1978,  -57.8549,  -53.6432,  -55.5394,  -56.9440,  -58.1495,\n",
       "          -19.8601,  -78.7014,  -67.7584,  -65.6570],\n",
       "        [ -36.0211,  -39.3716,  -40.7344,  -41.2396,  -50.4509,  -44.4773,\n",
       "          -40.1310,  -57.9925,   -7.0691,  -37.3422],\n",
       "        [ -23.0272,  -32.9326,  -38.2931,  -37.1798,  -38.6518,  -37.9601,\n",
       "          -33.6740,  -50.9740,   -4.8624,  -29.3589],\n",
       "        [ -23.0611,  -24.7625,  -35.3296,  -21.3650,  -28.3270,  -16.2022,\n",
       "          -31.0285,  -41.7051,   -8.6769,  -13.5487],\n",
       "        [ -40.3122,  -66.0101,  -14.3148,  -36.8314,  -48.9541,  -38.8731,\n",
       "          -46.8695,  -62.3126,  -56.4362,  -46.9378],\n",
       "        [ -44.0155,  -51.2613,  -57.9652,  -42.0091,  -56.9196,  -44.6244,\n",
       "          -64.5778,  -65.4846,  -64.4629,  -15.6212],\n",
       "        [ -23.3647,  -22.6276,  -12.7771,   -1.9310,  -17.4674,   -8.2309,\n",
       "          -19.7271,  -25.4802,  -23.6140,  -25.3271],\n",
       "        [ -50.6457,  -44.6075,  -32.7863,  -29.2652,  -36.0000,  -13.1005,\n",
       "          -38.3569,  -34.7254,  -52.4912,  -47.5747],\n",
       "        [ -29.0195,  -35.8387,  -34.6847,  -37.7004,  -47.7271,  -40.1731,\n",
       "          -55.3952,  -51.1770,   -6.0877,  -37.4167],\n",
       "        [ -17.0817,  -41.1740,  -54.0878,  -55.5029,  -45.1036,  -42.6179,\n",
       "          -49.2959,  -44.7521,  -14.5253,  -36.6776],\n",
       "        [ -53.1319,   -5.4853,  -58.3109,  -37.7210,  -58.0281,  -55.9738,\n",
       "          -63.7247,  -73.4184,  -50.6556,  -59.7369],\n",
       "        [ -85.6873,  -17.1900,  -67.7152,  -59.9754,  -74.2964,  -56.9760,\n",
       "          -74.4427,  -94.4863,  -74.9552,  -81.1496],\n",
       "        [ -82.4479, -103.6781,  -71.1936,  -63.7389,  -70.5024,  -65.0374,\n",
       "          -81.4814,  -12.4411,  -92.8427,  -79.5293],\n",
       "        [ -52.4043,  -65.7240,  -13.9007,  -39.0817,  -45.6828,  -37.2933,\n",
       "          -46.9286,  -53.2233,  -52.4183,  -52.6403],\n",
       "        [ -47.0599,  -48.3068,  -38.6964,  -38.1488,  -41.1106,  -18.2215,\n",
       "          -42.9390,  -37.3259,  -48.8486,  -57.4046],\n",
       "        [ -21.6672,  -46.8114,   -5.1022,  -20.5334,  -14.8323,  -16.4025,\n",
       "          -19.6476,  -31.0047,  -32.7949,  -33.3165],\n",
       "        [ -43.9671,  -56.0972,  -45.3276,  -32.6949,  -47.1284,  -34.0907,\n",
       "          -49.0492,   -4.9880,  -47.0843,  -49.6495],\n",
       "        [ -40.1609,  -50.1361,  -54.8299,  -65.9603,  -62.9768,  -56.5326,\n",
       "          -70.0286,  -59.5476,  -14.2556,  -48.7183],\n",
       "        [ -46.5954,  -30.2803,  -47.6154,  -48.9122,  -52.7907,  -59.9271,\n",
       "          -38.8219,  -70.5139,  -33.7682,   -9.5688],\n",
       "        [ -23.9961,  -72.4249,  -58.8255,  -72.2088,  -66.5885,  -64.0336,\n",
       "          -65.2252,  -83.6291,  -73.9042,  -86.4472],\n",
       "        [ -23.9743,  -24.8604,  -12.1263,   -1.4756,  -18.8832,   -6.5377,\n",
       "          -19.3431,  -24.5246,  -19.0951,  -30.1572],\n",
       "        [ -41.3553,  -42.5556,  -52.9726,  -40.6841,  -39.6299,  -33.0247,\n",
       "          -67.6318,  -54.0105,  -10.4198,  -47.6415],\n",
       "        [ -72.0442,  -71.4959,  -59.6545,  -73.2091,  -69.3209,  -56.8285,\n",
       "          -27.2589,  -85.0369,  -76.4927,  -80.9388],\n",
       "        [ -33.7598,  -38.3886,  -35.9682,  -37.8696,   -7.3045,  -33.4465,\n",
       "          -30.0878,  -36.9970,  -38.1942,  -49.3370],\n",
       "        [ -29.5683,  -17.1372,  -11.6256,   -4.4751,   -9.6523,   -7.0251,\n",
       "           -5.2301,  -22.0457,  -20.6049,  -18.3032],\n",
       "        [ -51.8266,  -49.0685,  -34.0440,  -33.9945,  -18.8425,  -48.5483,\n",
       "          -17.0987,  -63.8339,  -39.5388,  -53.1238],\n",
       "        [ -12.1082,  -26.2288,  -19.1285,  -21.3103,  -26.6243,  -28.5727,\n",
       "          -27.8946,  -49.1261,   -1.8304,  -28.3340],\n",
       "        [ -24.7385,  -96.6013,  -56.4603,  -70.1222,  -63.2873,  -66.3360,\n",
       "          -79.6578,  -69.9041,  -73.6068,  -73.1633],\n",
       "        [ -68.1929,  -76.6116,  -61.7371,  -63.8290,  -69.5595,  -60.8226,\n",
       "          -68.8476,  -11.6949,  -82.0763,  -81.5412]], device='cuda:1',\n",
       "       grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odin.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = odin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "odin.cpu()\n",
    "torch.save(odin, 'SavedModels/other/' + 'mahalanobis_CIFAR10' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.mahalanobis' from '/home/alexm/project/notebooks/gmm-robust/utils/mahalanobis.py'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
