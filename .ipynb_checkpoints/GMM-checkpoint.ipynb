{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import model_params as params\n",
    "import utils.resnet_orig as resnet\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "#import utils.gmm as GMM\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:6')\n",
    "# gmm = torch.load('SavedModels/GMM/gmm_MNIST_n1000_data_used60000_augm_flagTrue_alg_scikit.pth').to(device)\n",
    "gmm = models.GMM(500, 784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dl.MNIST(train=True, batch_size=512, augm_flag=True)\n",
    "test_loader = dl.MNIST(train=False, augm_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "param_groups = [{'params':gmm.mu,'lr':lr, 'weight_decay':0.},\n",
    "                {'params':gmm.logvar,'lr':lr, 'weight_decay':0.}]\n",
    "optimizer = optim.SGD(param_groups,  momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (data, _) = enumerate(train_loader).__next__()\n",
    "gmm.mu.data = data[:gmm.K].view(-1, 784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.NLLLoss()\n",
    "gmm.train()\n",
    "\n",
    "train_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = torch.logsumexp( gmm(data.view(data.shape[0], -1)), 0 ) - 625.7730167\n",
    "    loss_CEDA = torch.logsumexp(gmm(torch.rand(100, 784, device=device)), 0).mean()\n",
    "    loss_CEDA = 0.\n",
    "    loss = -output.sum()/train_loader.batch_size + loss_CEDA\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3462, device='cuda:6', grad_fn=<MeanBackward1>)\n",
      "tensor(0.1278, device='cuda:6', grad_fn=<MeanBackward1>)\n",
      "-2692.7284622192383\n",
      "tensor(-901.4057, device='cuda:6', grad_fn=<MeanBackward1>)\n",
      "tensor(1.3543, device='cuda:6')\n",
      "(tensor(209.8118, device='cuda:6'), tensor(411, device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "print(gmm.logvar.mean())\n",
    "print(gmm.mu.mean())\n",
    "print(train_loss)\n",
    "print(output.mean())\n",
    "print(gmm.mu.grad.abs().max())\n",
    "print(gmm.logvar.grad.abs().max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51.6443, device='cuda:6', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.5722, device='cuda:6', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(output.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, min_conf=.1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0.\n",
    "    av_conf = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            c, pred = output.max(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += (pred.eq(target.view_as(pred))*(c.exp()>min_conf)).sum().item()\n",
    "            av_conf += c.exp().sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    av_conf /= len(test_loader.dataset)\n",
    "    correct /= len(test_loader.dataset)\n",
    "    \n",
    "    return correct, av_conf, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(924.5433, device='cuda:6', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.models' from '/home/alexm/project/notebooks/gmm-robust/utils/models.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
