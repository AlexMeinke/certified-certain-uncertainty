{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87ba536c6e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugm_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def train(model, device, train_loader, optimizer, epoch, \n",
      "\u001b[0;32m~/project/notebooks/gmm-robust/model_params.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, augm_flag, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m              \u001b[0;34m(\u001b[0m\u001b[0;34m'EMNIST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m              \u001b[0;34m(\u001b[0m\u001b[0;34m'GrayCIFAR10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrayCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m              \u001b[0;34m(\u001b[0m\u001b[0;34m'Noise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m              ('UniformNoise', dl.UniformNoise(self.data_name, batch_size=batch_size))]\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/notebooks/gmm-robust/utils/dataloaders.py\u001b[0m in \u001b[0;36mNoise\u001b[0;34m(dataset, train, batch_size)\u001b[0m\n\u001b[1;32m    134\u001b[0m     loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n\u001b[1;32m    135\u001b[0m                                          shuffle=False, num_workers=4)\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrecomputeLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/notebooks/gmm-robust/utils/dataloaders.py\u001b[0m in \u001b[0;36mPrecomputeLoader\u001b[0;34m(loader, batch_size, shuffle)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "import model_params as params\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import utils.mc_dropout as mc\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Define hyperparameters.', prefix_chars='-')\n",
    "\n",
    "#parser.add_argument('--gpu', type=int, default=0, help='GPU index.')\n",
    "#parser.add_argument('--dataset', type=str, default='MNIST', help='MNIST, FMNIST, SVHN, CIFAR10, CIFAR100')\n",
    "\n",
    "\n",
    "#hps = parser.parse_args()\n",
    "\n",
    "\n",
    "dataset = 'MNIST'\n",
    "\n",
    "saving_string = dataset + '_base'\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, \n",
    "          verbose=100, noise_loader=None, epsilon=.3):\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        #output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        if (batch_idx % verbose == 0) and verbose>0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return train_loss/len(train_loader.dataset), correct/len(train_loader.dataset)\n",
    "\n",
    "\n",
    "if dataset=='MNIST':\n",
    "    model = mc.LeNet()\n",
    "elif dataset=='FMNIST':\n",
    "    model = mc.vgg13(in_channels=1, num_classes=10)\n",
    "elif dataset in ['SVHN', 'CIFAR10']:\n",
    "    model = mc.vgg13(in_channels=3, num_classes=10)\n",
    "elif dataset=='CIFAR100':\n",
    "    model = mc.vgg13(in_channels=3, num_classes=100)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "param_groups = [{'params':model.parameters(),'lr':model_params.lr, 'weight_decay':5e-4}]\n",
    "    \n",
    "if dataset=='MNIST':\n",
    "    optimizer = optim.Adam(param_groups)\n",
    "else: \n",
    "    optimizer = optim.SGD(param_groups, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    if epoch+1 in [50,75,90]:\n",
    "        for group in optimizer.param_groups:\n",
    "            group['lr'] *= .1\n",
    " \n",
    "    trainloss, correct_train = train(model, device, model_params.train_loader,  \n",
    "                                     optimizer, epoch, verbose=-1)\n",
    "    print(str(epoch) + ': \\t' + str(correct_train))\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "mc_model = mc.MC_Model(model, iterations=10, classes=model_params.classes)\n",
    "\n",
    "torch.save(mc_model, 'SavedModels/other/mcdo/' + dataset + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MC_Model(\n",
       "  (model): LeNet(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    (dropout): MC_dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mc)\n",
    "mc_model = mc.MC_Model(model, iterations=7, classes=model_params.classes)\n",
    "mc_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4970)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(mc_model, 'SavedModels/other/mcdo/' + dataset + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9563,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9895,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5617,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9698,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9924,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7467,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9423,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9794,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9213,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9823,\n",
       "         0.0000]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000.*mc_model(x)).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(model_params.test_loader))[0]\n",
    "out_data = next(iter(model_params.loaders[0][1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -3.5947e-09,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -3.7253e-05,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -4.7048e-06,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [-2.2564e-04,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -4.4497e-07,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -5.5477e-07,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -2.7228e-05,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -2.6306e-03],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -1.7423e+00,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -3.6500e-04],\n",
       "        [-8.0702e-05,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -4.2973e-03,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -3.1490e-04],\n",
       "        [-1.2764e-04,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -1.9987e-06,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -1.1256e-02,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -9.4132e-04],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.6824e-06,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -1.0003e-02,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -2.0664e-06,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -7.0897e-03],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -2.5729e-07,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -1.1516e-03,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -2.7359e-05,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -1.0354e-04,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [-2.7719e-04,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -4.8088e-06,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -2.9016e-10,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [-2.1362e-03,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -3.3105e-05,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -2.1756e-08,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -2.8105e-04,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -3.0867e-07,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -5.8636e-05,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.5017e-09,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -1.7992e-03,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -2.1974e-04,        -inf,        -inf],\n",
       "        [       -inf, -2.9074e-05,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -6.0161e-03,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -4.1546e-08,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -1.8858e-02,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -4.7156e-03,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -1.9037e-06,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -2.4634e-02,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -3.8322e-04,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -5.3197e-05,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -1.6494e-03,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -1.7596e-07,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -1.2204e-04,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -3.2625e-06,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -3.1763e-06,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -1.7847e-05,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -6.9020e-07,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -9.8747e-04,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -3.1524e-05,        -inf,        -inf,        -inf],\n",
       "        [-4.6519e-05,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -1.2041e-11,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -7.8917e-06,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -6.6992e-05],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "         -1.2598e-03,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.4974e-08,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf, -9.3089e-07,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -7.7195e-01],\n",
       "        [       -inf,        -inf,        -inf, -2.8492e-01,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -5.7191e-07,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -3.2195e-04,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -3.8414e-02,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -7.1425e-02,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -2.6825e-08,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [-2.3470e-05,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.3455e-03,        -inf,        -inf],\n",
       "        [-1.3668e-07,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -9.4215e-07,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -2.5586e-03],\n",
       "        [       -inf, -2.6580e-05,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -5.1339e-05,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -6.8476e-08,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -4.2176e-05,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -2.2622e+00],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -2.8994e-07,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.1792e-02,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -1.7778e-07,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf, -9.7399e-07,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -6.9830e-06,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf, -6.8501e-03,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -7.3471e-06,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -1.0973e-06,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -3.2688e-01,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -2.6395e-06,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -3.3024e-05,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, -1.0351e-07,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -3.5380e-06,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -4.6889e-02],\n",
       "        [       -inf,        -inf,        -inf, -3.3169e-04,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -7.3986e-06,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf, -1.1770e-02,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf, -5.5380e-02,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf, -3.8815e-09,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf, -5.8911e-05,        -inf,        -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
       "                -inf,        -inf,        -inf,        -inf, -1.1600e-05]],\n",
       "       grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.4988, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_model(x).max(1)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.4220, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_model(out_data).max(1)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.3726,  -7.9268,  -4.8141,  -7.6775,  -6.1880,  -7.2239,  -4.5580,\n",
       "          -9.6222,  -0.0298,  -6.0110],\n",
       "        [ -4.0340,  -6.3577,  -2.2455,  -5.0191,  -4.6770,  -6.3202,  -2.3114,\n",
       "          -6.5509,  -0.2848,  -5.4524],\n",
       "        [ -5.2128,  -6.9789,  -3.8566,  -5.2700,  -6.3310,  -7.1379,  -3.7537,\n",
       "          -8.5233,  -0.0652,  -5.4509],\n",
       "        [ -6.4082,  -8.8897,  -3.7003,  -6.9389,  -7.3992,  -8.7028,  -4.6785,\n",
       "         -10.2759,  -0.0408,  -6.0173],\n",
       "        [ -3.8536,  -6.0161,  -2.8637,  -3.7964,  -5.4262,  -5.1880,  -2.9985,\n",
       "          -7.1351,  -0.1996,  -4.0651],\n",
       "        [ -5.1228,  -6.6619,  -4.1636,  -5.2017,  -5.4402,  -6.0420,  -4.3007,\n",
       "          -7.0575,  -0.0623,  -4.5131],\n",
       "        [ -4.2476,  -5.9894,  -3.0897,  -5.1981,  -4.7528,  -5.6720,  -3.7552,\n",
       "          -6.8968,  -0.1245,  -4.3644],\n",
       "        [ -3.8885,  -5.1258,  -2.5800,  -4.3765,  -4.1712,  -4.9954,  -2.9889,\n",
       "          -5.7543,  -0.2370,  -3.8859],\n",
       "        [ -4.5326,  -6.3336,  -3.2776,  -5.1054,  -4.6792,  -5.4274,  -3.1316,\n",
       "          -6.6649,  -0.1270,  -5.4284],\n",
       "        [ -4.2652,  -5.9849,  -1.9099,  -5.0449,  -6.6527,  -7.0331,  -4.4589,\n",
       "          -6.7538,  -0.2148,  -4.9265]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_model.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9408, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = []\n",
    "for _ in range(7):\n",
    "    out.append(mc_model.model(data).exp())\n",
    "out = torch.stack(out)\n",
    "y = out.mean(0)\n",
    "\n",
    "1000*((out - y[None,:,:])**2).mean(0).sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "import model_params as params\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import utils.mc_dropout as mc\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multindex = pd.DataFrame(stats_dict,\n",
    "                             index=[len(metrics)*['MNIST'],\n",
    "                                    metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "      &     &       CCU &      base \\\\\n",
      "\\midrule\n",
      "MNIST & TE &  0.999426 &  0.428961 \\\\\n",
      "      & MMC &  0.789796 &  0.878765 \\\\\n",
      "      & SR &  0.310605 &  0.268120 \\\\\n",
      "      & AUC &  0.114866 &  0.535991 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_multindex.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['base', 'CCU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base', 'CCU']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = torch.rand(2, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('base',\n",
       "              [0.4289613962173462,\n",
       "               0.8787645101547241,\n",
       "               0.26811957359313965,\n",
       "               0.535990834236145]),\n",
       "             ('CCU',\n",
       "              [0.9994264245033264,\n",
       "               0.7897958755493164,\n",
       "               0.31060510873794556,\n",
       "               0.11486554145812988])])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict = collections.OrderedDict(zip(models, stats[:,:,0].tolist()))\n",
    "stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "CCU\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(models, stats[:,:,0].tolist()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4290],\n",
       "         [0.8788],\n",
       "         [0.2681],\n",
       "         [0.5360]],\n",
       "\n",
       "        [[0.9994],\n",
       "         [0.7898],\n",
       "         [0.3106],\n",
       "         [0.1149]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'SavedModels/other/mcdo/FMNIST.pth'\n",
    "model = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'results/backup/samples_steps500_alpha3.0_restarts50_batches2_batch_size50_FMNIST_2019-09-09 14:19:01.427238_FMNIST.pth'\n",
    "stats = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50, 1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.seeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.8868e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(stats.seeds[0]).max(1)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(stats.samples[0,0]).max(1)[0].exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'SavedModels/other/mcdo/MNIST.pth'\n",
    "model = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.mc_dropout' from '/home/alexm/project/notebooks/gmm-robust/utils/mc_dropout.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.8848e+00, -1.1595e+01, -6.0736e+00, -9.5124e+00, -9.5232e+00,\n",
       "         -9.6294e+00, -7.7080e+00, -1.2109e+01, -3.5944e-03, -8.3685e+00],\n",
       "        [-8.5293e+00, -1.0281e+01, -6.0877e+00, -7.1184e+00, -8.3114e+00,\n",
       "         -7.4821e+00, -7.1142e+00, -1.1321e+01, -5.1584e-03, -8.5258e+00],\n",
       "        [-8.0917e+00, -1.1280e+01, -7.2941e+00, -8.9765e+00, -7.9143e+00,\n",
       "         -9.8949e+00, -9.6573e+00, -1.1163e+01, -2.4381e-03, -7.1104e+00],\n",
       "        [-7.1958e+00, -9.4005e+00, -4.7116e+00, -7.9325e+00, -5.7638e+00,\n",
       "         -8.7296e+00, -7.2347e+00, -9.8245e+00, -1.4677e-02, -8.0719e+00],\n",
       "        [-1.1978e+01, -1.3703e+01, -9.5455e+00, -1.0807e+01, -1.1731e+01,\n",
       "         -1.0837e+01, -9.4580e+00, -1.4891e+01, -2.1172e-04, -1.1890e+01],\n",
       "        [-1.0263e+01, -1.3445e+01, -8.7900e+00, -9.9919e+00, -1.1504e+01,\n",
       "         -1.0646e+01, -9.1092e+00, -1.5402e+01, -3.9101e-04, -1.1337e+01],\n",
       "        [-9.1353e+00, -1.1820e+01, -8.2553e+00, -9.3483e+00, -9.7158e+00,\n",
       "         -9.2500e+00, -7.9322e+00, -1.3153e+01, -1.0996e-03, -9.0312e+00],\n",
       "        [-8.6961e+00, -1.1773e+01, -6.9860e+00, -9.2141e+00, -1.1183e+01,\n",
       "         -1.1864e+01, -8.4501e+00, -1.2520e+01, -1.4629e-03, -1.0631e+01],\n",
       "        [-9.2485e+00, -1.0725e+01, -7.4647e+00, -7.8567e+00, -9.2922e+00,\n",
       "         -9.7957e+00, -7.9230e+00, -1.2086e+01, -1.8244e-03, -8.3855e+00],\n",
       "        [-8.9166e+00, -1.1581e+01, -8.0000e+00, -8.9992e+00, -9.0028e+00,\n",
       "         -9.8535e+00, -8.9183e+00, -1.2814e+01, -1.1940e-03, -8.1874e+00]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \t0.5813666666666667\n",
      "1: \t0.7779833333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-301a2ee7ac0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     trainloss, correct_train = train(model, device, model_params.train_loader,  \n\u001b[0;32m---> 97\u001b[0;31m                                      optimizer, epoch, verbose=-1)\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': \\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-301a2ee7ac0c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, verbose, noise_loader, epsilon)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "import model_params as params\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import utils.mc_dropout as mc\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "dataset = 'FMNIST'\n",
    "\n",
    "saving_string = dataset + '_base'\n",
    "device = torch.device('cuda:4')\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, \n",
    "          verbose=100, noise_loader=None, epsilon=.3):\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        #output = F.log_softmax(model(data), dim=1)\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        if (batch_idx % verbose == 0) and verbose>0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return train_loss/len(train_loader.dataset), correct/len(train_loader.dataset)\n",
    "\n",
    "\n",
    "if dataset=='MNIST':\n",
    "    model = mc.LeNet()\n",
    "elif dataset=='FMNIST':\n",
    "    model = mc.vgg13(in_channels=1, num_classes=10)\n",
    "elif dataset in ['SVHN', 'CIFAR10']:\n",
    "    model = mc.vgg13(in_channels=3, num_classes=10)\n",
    "elif dataset=='CIFAR100':\n",
    "    model = mc.vgg13(in_channels=3, num_classes=100)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "lr = model_params.lr\n",
    "lr = 2e-4\n",
    "param_groups = [{'params':model.parameters(),'lr':lr, 'weight_decay':0.}]\n",
    "    \n",
    "if dataset=='MNIST':\n",
    "    optimizer = optim.Adam(param_groups)\n",
    "else: \n",
    "    optimizer = optim.SGD(param_groups, momentum=0.9)\n",
    "\n",
    "    \n",
    "optimizer = optim.Adam(param_groups)\n",
    "\n",
    "for epoch in range(100):\n",
    "    if epoch+1 in [50,75,90]:\n",
    "        for group in optimizer.param_groups:\n",
    "            group['lr'] *= .1\n",
    " \n",
    "    trainloss, correct_train = train(model, device, model_params.train_loader,  \n",
    "                                     optimizer, epoch, verbose=-1)\n",
    "    print(str(epoch) + ': \\t' + str(correct_train))\n",
    "\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = mc.MC_Model(model, iterations=10, classes=model_params.classes)\n",
    "\n",
    "torch.save(mc_model, 'SavedModels/other/mcdo/' + dataset + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_params' from '/home/alexm/project/notebooks/gmm-robust/model_params.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1001, 0.1009, 0.1009, 0.1015, 0.0988, 0.1009, 0.1009, 0.0957, 0.0985,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1009, 0.1009, 0.1014, 0.0987, 0.1008, 0.1009, 0.0957, 0.0986,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1008, 0.1011, 0.1015, 0.0988, 0.1008, 0.1008, 0.0957, 0.0985,\n",
       "         0.1020],\n",
       "        [0.1001, 0.1008, 0.1009, 0.1014, 0.0988, 0.1008, 0.1009, 0.0957, 0.0986,\n",
       "         0.1020],\n",
       "        [0.1001, 0.1009, 0.1010, 0.1014, 0.0988, 0.1008, 0.1009, 0.0957, 0.0985,\n",
       "         0.1020],\n",
       "        [0.1000, 0.1009, 0.1009, 0.1014, 0.0988, 0.1009, 0.1009, 0.0957, 0.0986,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1009, 0.1010, 0.1014, 0.0988, 0.1008, 0.1008, 0.0957, 0.0985,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1009, 0.1010, 0.1015, 0.0988, 0.1008, 0.1008, 0.0958, 0.0985,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1009, 0.1009, 0.1014, 0.0988, 0.1008, 0.1008, 0.0958, 0.0985,\n",
       "         0.1019],\n",
       "        [0.1001, 0.1009, 0.1010, 0.1014, 0.0988, 0.1008, 0.1008, 0.0957, 0.0985,\n",
       "         0.1019]], device='cuda:4', grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(10,1,28,28,device=device)).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.dataloaders' from '/home/alexm/project/notebooks/gmm-robust/utils/dataloaders.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dl.TinyImages('MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6662, 0.2200, 0.8140, 0.3196, 0.8920, 0.0562, 0.4096, 0.1929, 0.5605,\n",
       "        0.1893])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3196)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('SavedModels/other/mcdo/SVHN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace)\n",
       "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MC_dropout(p=0.5)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MC_dropout(p=0.5)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.maha_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
