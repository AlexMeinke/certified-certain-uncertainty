{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import utils.confident_classifier as cc\n",
    "import utils.dataloaders as dl\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../Confident_classifier/SavedModels/'\n",
    "\n",
    "# MNIST\n",
    "file = 'MNIST_epochs100_lr0.0002_classifier.pth'\n",
    "model = cc.LeNet()\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'MNIST' + '.pth')\n",
    "\n",
    "\n",
    "# FMNIST\n",
    "file = 'FMNIST_epochs100_lr0.0002_classifier.pth'\n",
    "file = 'FMNIST_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=1, num_classes=10)\n",
    "model = cc.vgg13(in_channels=1, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'FMNIST' + '.pth')\n",
    "\n",
    "\n",
    "# SVHN\n",
    "file = 'SVHN_epochs100_lr0.0002_classifier.pth'\n",
    "file = 'SVHN_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=3, num_classes=10)\n",
    "model = cc.vgg13(in_channels=3, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'SVHN' + '.pth')\n",
    "\n",
    "\n",
    "# CIFAR10\n",
    "file = 'CIFAR10_epochs100_lr0.0002_classifier.pth'\n",
    "file = 'CIFAR10_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=3, num_classes=10)\n",
    "model = cc.vgg13(in_channels=3, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'CIFAR10' + '.pth')\n",
    "\n",
    "\n",
    "# CIFAR100\n",
    "file = 'CIFAR100_epochs100_lr0.0002_classifier.pth'\n",
    "file = 'CIFAR100_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=3, num_classes=100)\n",
    "model = cc.vgg13(in_channels=3, num_classes=100)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'CIFAR100' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = dl.CIFAR10(train=False)\n",
    "data = next(iter(test_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5800)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(data).exp().max(1)[0] == 1.).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.confident_classifier' from '/home/alexm/project/notebooks/gmm-robust/utils/confident_classifier.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../Confident_classifier/SavedModels/'\n",
    "\n",
    "# FMNIST\n",
    "file = 'FMNIST_epochs100_lr0.0002_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=1, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'FMNIST' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(dl.FMNIST(train=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-3.8147e-06, -5.7220e-06, -2.2888e-05, -1.4305e-05, -1.1421e-02,\n",
       "        -2.8610e-06, -1.0872e-04,  0.0000e+00, -4.7684e-06, -2.2888e-05,\n",
       "        -5.2071e-03, -2.8610e-06, -1.5864e-03, -8.5831e-06, -1.2398e-04,\n",
       "        -9.5367e-07, -7.8678e-05, -3.3856e-01,  0.0000e+00, -9.5367e-07,\n",
       "        -1.7166e-04,  0.0000e+00, -2.8610e-06, -2.0854e-01, -6.9618e-05,\n",
       "        -1.4315e-01, -1.8978e-04, -3.6240e-05, -9.5367e-07,  0.0000e+00,\n",
       "        -8.5831e-06,  0.0000e+00, -7.2479e-05, -1.7071e-04,  0.0000e+00,\n",
       "         0.0000e+00, -9.5367e-07, -1.9073e-06, -1.1444e-05, -1.9073e-06,\n",
       "        -6.6309e-03, -3.5286e-05, -3.2338e-02, -5.1602e-01, -2.8610e-06,\n",
       "        -3.8147e-06, -3.0518e-05, -2.1935e-05, -6.1989e-04, -1.1063e-04,\n",
       "        -9.5367e-07, -2.8610e-06, -1.9073e-06,  0.0000e+00,  0.0000e+00,\n",
       "        -2.8610e-06,  0.0000e+00,  0.0000e+00, -1.9073e-06, -1.9073e-06,\n",
       "        -1.5259e-05, -8.5831e-06, -1.0490e-05, -2.0027e-05, -2.5749e-05,\n",
       "        -4.7684e-06, -1.0490e-05, -2.2125e-04, -4.7684e-06, -9.5367e-07,\n",
       "         0.0000e+00, -7.6294e-06, -1.4305e-05, -3.8147e-06, -2.8610e-06,\n",
       "        -8.8692e-05, -1.7166e-05, -5.7220e-06, -3.8147e-06, -1.9073e-06,\n",
       "        -1.0490e-05,  0.0000e+00, -1.9073e-06, -1.9073e-06, -2.8610e-06,\n",
       "        -5.7220e-06,  0.0000e+00,  0.0000e+00, -3.8147e-06, -2.0520e-01,\n",
       "        -7.6294e-06, -9.5367e-07,  0.0000e+00, -1.2398e-05, -7.6294e-06,\n",
       "        -3.5538e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3575e-02],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 6, 8, 0, 2, 5, 7, 9,\n",
       "        1, 6, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
       "        2, 6, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 7, 8, 7, 0,\n",
       "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
       "        0, 1, 4, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
       "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
       "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
       "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
       "        0, 1, 4, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.traintest as tt\n",
    "\n",
    "train_loader = dl.FMNIST(train=True, augm_flag=False)\n",
    "test_loader = dl.FMNIST(train=False)\n",
    "device = torch.device('cuda:6')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9441, 0.2775946253458659, 1.3951829559326172)\n",
      "(0.8856, 0.26341401767730716, 1.472379734802246)\n"
     ]
    }
   ],
   "source": [
    "res = tt.test(model, device, train_loader)\n",
    "print(res)\n",
    "\n",
    "res = tt.test(model, device, test_loader)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9441, 0.27759462509155275, 1.3951829630533854)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'FMNIST_epochs100_lr0.0002_classifier.pth'\n",
    "model = cc.ResNet18(num_of_channels=1, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
