{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import resnet\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import params as hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:' + str(hps.gpu))\n",
    "writer = SummaryWriter()\n",
    "\n",
    "if hps.dataset=='MNIST':\n",
    "    base_model = models.LeNetMadry().to(device)\n",
    "    train_loader = dl.MNIST_train_loader\n",
    "    noise_loader = dl.Noise_train_loader_MNIST\n",
    "elif hps.dataset=='CIFAR10':\n",
    "    base_model = resnet.ResNet50().to(device).to(device)\n",
    "    train_loader = dl.CIFAR10_train_loader\n",
    "    noise_loader = dl.Noise_train_loader_CIFAR10\n",
    "    \n",
    "noise_loader = dl.PrecomputeLoader(noise_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if hps.use_gmm:\n",
    "    loading_string = hps.dataset+'_n'+str(hps.n) \n",
    "    gmm = torch.load('SavedModels/gmm_'+loading_string+'.pth')\n",
    "    gmm.alpha = nn.Parameter(gmm.alpha)\n",
    "    model = models.RobustModel(base_model, gmm, -5.).to(device)\n",
    "    model.loglam.requires_grad = False\n",
    "else:\n",
    "    model = base_model\n",
    "\n",
    "saving_string = hps.dataset+'_lam'+str(hps.lam)+'_n'+str(hps.n)\n",
    "\n",
    "\n",
    "\n",
    "lr = .1*hps.lr\n",
    "\n",
    "if hps.use_gmm:\n",
    "    param_groups = [{'params':model.base_model.parameters(),'lr':lr, 'weight_decay':hps.decay},\n",
    "                   {'params':model.mm.parameters(),'lr':lr, 'weight_decay':0.}]\n",
    "else:\n",
    "    param_groups = [{'params':model.parameters(),'lr':lr, 'weight_decay':hps.decay}]\n",
    "    \n",
    "optimizer = optim.Adam(param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataloaders as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "loader = dl.SVHN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(loader).__next__()[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
