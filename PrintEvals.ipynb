{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.models as models\n",
    "import utils.plotting as plotting\n",
    "import utils.dataloaders as dl\n",
    "import utils.traintest as tt\n",
    "import utils.adversarial as adv\n",
    "import utils.eval as ev\n",
    "import model_params as params\n",
    "import utils.resnet_orig as resnet\n",
    "import utils.gmm_helpers as gmm_helpers\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats(model, device, model_params):\n",
    "    print(tt.test(model, device, model_params.test_loader, min_conf=.101)[0])\n",
    "    df = ev.evaluate(model, device, model_params.data_name, model_params.loaders)\n",
    "    return df\n",
    "\n",
    "def evaluate(model_params, device, file_joint, file_base, file_gmm):\n",
    "    model_joint = torch.load('SavedModels/' + file_joint).to(device)\n",
    "    model_joint.eval()\n",
    "\n",
    "    df_joint = show_stats(model_joint, device, model_params)\n",
    "    df_joint_base = show_stats(model_joint.base_model, device, model_params)\n",
    "\n",
    "    base_model = torch.load('SavedModels/base/' + file_base)\n",
    "    gmm = torch.load('SavedModels/GMM/' + file_gmm)\n",
    "\n",
    "    lam = model_joint.loglam\n",
    "    model = models.RobustModel(base_model, gmm, lam, dim=model_params.dim).to(device)\n",
    "    model.train()\n",
    "\n",
    "    df_sep = show_stats(model, device, model_params)\n",
    "    df_sep_base = show_stats(model.base_model, device, model_params)\n",
    " \n",
    "    df1 = pd.concat([df_sep_base, df_sep], axis=1, keys=['Base', 'GMM'])\n",
    "    df2 = pd.concat([df_joint_base, df_joint], axis=1, keys=['Base', 'GMM'])\n",
    "    return df1, df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944\n",
      "0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n",
      "0.9951\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &  FPR@95 &       MMC &     AUROC &  FPR@95 \\\\\n",
      "DataSet     &           &           &         &           &           &         \\\\\n",
      "\\midrule\n",
      "orig        &  0.991786 &         - &       - &  0.991171 &         - &       - \\\\\n",
      "FMNIST      &  0.690625 &  0.979117 &  0.1705 &  0.275835 &  0.991394 &  0.0718 \\\\\n",
      "EMNIST      &  0.819703 &  0.897694 &  0.4125 &  0.805450 &  0.896055 &  0.4052 \\\\\n",
      "GrayCIFAR10 &  0.481831 &  0.996559 &  0.0045 &  0.100124 &  0.999699 &       0 \\\\\n",
      "Noise       &  0.124669 &  0.999997 &       0 &  0.104590 &  0.999548 &       0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &  FPR@95 &       MMC &     AUROC &  FPR@95 \\\\\n",
      "DataSet     &           &           &         &           &           &         \\\\\n",
      "\\midrule\n",
      "orig        &  0.991447 &         - &       - &  0.991363 &         - &       - \\\\\n",
      "FMNIST      &  0.531909 &  0.991687 &  0.0631 &  0.384236 &  0.993831 &  0.0528 \\\\\n",
      "EMNIST      &  0.803225 &  0.902104 &  0.3796 &  0.800994 &   0.89965 &  0.3781 \\\\\n",
      "GrayCIFAR10 &  0.193603 &  0.999812 &       0 &  0.100200 &  0.999948 &       0 \\\\\n",
      "Noise       &  0.123504 &  0.999998 &       0 &  0.105051 &  0.999928 &       0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'MNIST'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCAMNIST_lam0.0_n100_lr0.001_lrgmm0.001_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_MNIST_lr0.001_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_MNIST_n100_data_used60000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505\n",
      "0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9491\n",
      "0.951\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &     FPR@95 &       MMC &     AUROC &  FPR@95 \\\\\n",
      "DataSet     &           &           &            &           &           &         \\\\\n",
      "\\midrule\n",
      "orig        &  0.983704 &         - &          - &  0.983028 &         - &       - \\\\\n",
      "MNIST       &  0.678978 &  0.973733 &     0.1204 &  0.678978 &  0.972996 &  0.1204 \\\\\n",
      "EMNIST      &  0.659204 &  0.975426 &     0.1025 &  0.659204 &  0.974687 &  0.1025 \\\\\n",
      "GrayCIFAR10 &  0.864589 &  0.917606 &     0.4992 &  0.190792 &  0.991474 &  0.0448 \\\\\n",
      "Noise       &  0.502705 &  0.987545 &  0.0435937 &  0.339738 &  0.994042 &  0.0125 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &     FPR@95 &       MMC &     AUROC &     FPR@95 \\\\\n",
      "DataSet     &           &           &            &           &           &            \\\\\n",
      "\\midrule\n",
      "orig        &  0.984831 &         - &          - &  0.984134 &         - &          - \\\\\n",
      "MNIST       &  0.689281 &  0.973178 &     0.1423 &  0.689281 &  0.972414 &     0.1423 \\\\\n",
      "EMNIST      &  0.668332 &  0.974855 &     0.1281 &  0.668332 &  0.974087 &     0.1281 \\\\\n",
      "GrayCIFAR10 &  0.842169 &  0.930958 &     0.4563 &  0.187202 &  0.993422 &      0.038 \\\\\n",
      "Noise       &  0.549319 &  0.986982 &  0.0398437 &  0.383048 &  0.992726 &  0.0182812 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'FMNIST'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCAFMNIST_lam0.0_n100_lr0.1_lrgmm1e-05_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_FMNIST_lr0.1_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_FMNIST_n100_data_used60000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694222495390289\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.969460663798402\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663106945298094\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "0.9673862937922557\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &     FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &            \\\\\n",
      "\\midrule\n",
      "orig      &  0.984496 &         - &         - &  0.984469 &         - &          - \\\\\n",
      "CIFAR10   &  0.713052 &  0.945034 &    0.2088 &  0.567529 &  0.957556 &     0.1624 \\\\\n",
      "CIFAR100  &  0.712355 &  0.943244 &    0.2113 &  0.529989 &   0.95784 &     0.1544 \\\\\n",
      "LSUN\\_CR   &  0.715110 &  0.944422 &  0.226667 &  0.158671 &  0.995344 &  0.0166667 \\\\\n",
      "Imagenet- &  0.715440 &  0.943598 &    0.2181 &  0.209036 &  0.988872 &     0.0421 \\\\\n",
      "Noise     &  0.641172 &  0.965957 &  0.137542 &  0.637791 &   0.96632 &   0.136315 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &     FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &            \\\\\n",
      "\\midrule\n",
      "orig      &  0.983558 &         - &         - &  0.983466 &         - &          - \\\\\n",
      "CIFAR10   &  0.734127 &  0.940187 &    0.2331 &  0.556709 &  0.956595 &     0.1672 \\\\\n",
      "CIFAR100  &  0.733133 &  0.937214 &    0.2366 &  0.517231 &  0.957433 &     0.1592 \\\\\n",
      "LSUN\\_CR   &  0.715860 &  0.945878 &  0.233333 &  0.139244 &  0.997578 &  0.0133333 \\\\\n",
      "Imagenet- &  0.731286 &  0.938594 &    0.2345 &  0.196309 &  0.989632 &     0.0395 \\\\\n",
      "Noise     &  0.669768 &   0.96197 &  0.152478 &  0.666232 &  0.961427 &    0.15185 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'SVHN'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCASVHN_lam0.0_n100_lr0.1_lrgmm1e-06_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_SVHN_lr0.01_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_SVHN_n100_data_used50000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945\n",
      "0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9395\n",
      "0.9438\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &     FPR@95 &       MMC &     AUROC &     FPR@95 \\\\\n",
      "DataSet   &           &           &            &           &           &            \\\\\n",
      "\\midrule\n",
      "orig      &  0.970253 &         - &          - &  0.969627 &         - &          - \\\\\n",
      "SVHN      &  0.661050 &  0.952938 &     0.0993 &  0.661057 &  0.952185 &     0.0992 \\\\\n",
      "CIFAR100  &  0.792091 &  0.873726 &     0.3476 &  0.789369 &  0.873341 &     0.3463 \\\\\n",
      "LSUN\\_CR   &  0.738767 &  0.917583 &       0.24 &  0.727435 &  0.919578 &   0.233333 \\\\\n",
      "Imagenet- &  0.787178 &  0.868608 &     0.3414 &  0.724067 &  0.878997 &     0.3126 \\\\\n",
      "Noise     &  0.633381 &  0.960255 &  0.0782031 &  0.631463 &  0.960091 &  0.0711719 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &    FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &           &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.971488 &         - &         - &  0.970866 &         - &         - \\\\\n",
      "SVHN      &  0.743608 &   0.93352 &    0.1808 &  0.743614 &   0.93269 &    0.1806 \\\\\n",
      "CIFAR100  &  0.799839 &  0.870589 &    0.3626 &  0.797268 &  0.869972 &    0.3618 \\\\\n",
      "LSUN\\_CR   &  0.724355 &  0.920233 &  0.186667 &  0.712570 &  0.922961 &  0.176667 \\\\\n",
      "Imagenet- &  0.796798 &   0.86329 &    0.3572 &  0.734043 &  0.874355 &    0.3271 \\\\\n",
      "Noise     &  0.655060 &  0.946853 &  0.137734 &  0.654662 &  0.946504 &  0.135781 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'CIFAR10'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCACIFAR10_lam0.0_n100_lr0.1_lrgmm1e-05_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_CIFAR10_lr0.1_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_CIFAR10_n100_data_used50000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7646\n",
      "0.7649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexm/project/notebooks/gmm-robust/utils/models.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loglam = nn.Parameter(torch.tensor(loglam, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761\n",
      "0.7679\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &     FPR@95 &       MMC &     AUROC &     FPR@95 \\\\\n",
      "DataSet   &           &           &            &           &           &            \\\\\n",
      "\\midrule\n",
      "orig      &  0.806369 &         - &          - &  0.805886 &         - &          - \\\\\n",
      "SVHN      &  0.437698 &  0.842599 &     0.0459 &  0.437697 &   0.84203 &     0.0459 \\\\\n",
      "CIFAR10   &  0.522311 &   0.78657 &     0.1014 &  0.522312 &  0.785995 &     0.1016 \\\\\n",
      "LSUN\\_CR   &  0.467175 &  0.845067 &  0.0566667 &  0.467187 &  0.844972 &  0.0566667 \\\\\n",
      "Imagenet- &  0.489895 &  0.807401 &     0.0764 &  0.483806 &  0.809774 &     0.0757 \\\\\n",
      "Noise     &  0.532573 &  0.779823 &   0.120156 &  0.529522 &  0.781468 &   0.116328 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrllrll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{Base} & \\multicolumn{3}{l}{GMM} \\\\\n",
      "{} &       MMC &     AUROC &     FPR@95 &       MMC &     AUROC &    FPR@95 \\\\\n",
      "DataSet   &           &           &            &           &           &           \\\\\n",
      "\\midrule\n",
      "orig      &  0.838128 &         - &          - &  0.837716 &         - &         - \\\\\n",
      "SVHN      &  0.478947 &  0.854732 &     0.0487 &  0.478948 &  0.854249 &    0.0487 \\\\\n",
      "CIFAR10   &  0.582458 &  0.783272 &     0.1469 &  0.582460 &  0.782637 &     0.147 \\\\\n",
      "LSUN\\_CR   &  0.533045 &  0.834122 &       0.08 &  0.533034 &  0.834128 &      0.08 \\\\\n",
      "Imagenet- &  0.543225 &  0.809598 &     0.1086 &  0.537630 &  0.811509 &     0.108 \\\\\n",
      "Noise     &  0.589202 &  0.794053 &  0.0977344 &  0.597563 &  0.788888 &  0.103047 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "dataset = 'CIFAR100'\n",
    "\n",
    "model_params = params.params_dict[dataset](augm_flag=True, batch_size=128)\n",
    "\n",
    "file_joint = 'gmm__PCACIFAR100_lam0.0_n100_lr0.1_lrgmm1e-05_augm_flagTrue_train_typeCEDA_GMMgrad_vars mu var.pth'\n",
    "file_base = 'base_CIFAR100_lr0.1_augm_flagTrue_train_typeCEDA.pth'\n",
    "file_gmm = 'gmm_CIFAR100_n100_data_used50000_augm_flagTrue_alg_scikit_PCA.pth'\n",
    "\n",
    "df_sep, df_joint = evaluate(model_params, device, file_joint, file_base, file_gmm)\n",
    "print(df_joint.to_latex())\n",
    "print(df_sep.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
