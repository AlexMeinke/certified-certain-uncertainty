{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import GAN\n",
    "trained using  https://github.com/alinlab/Confident_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import utils.confident_classifier as cc\n",
    "\n",
    "\n",
    "folder = '../Confident_classifier/SavedModels/'\n",
    "\n",
    "# MNIST\n",
    "file = 'MNIST_epochs100_lr0.0002_classifier.pth'\n",
    "model = cc.LeNet()\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'MNIST' + '.pth')\n",
    "\n",
    "\n",
    "# FMNIST\n",
    "file = 'FMNIST_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.vgg13(in_channels=1, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'FMNIST' + '.pth')\n",
    "\n",
    "\n",
    "# SVHN\n",
    "file = 'SVHN_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.vgg13(in_channels=3, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'SVHN' + '.pth')\n",
    "\n",
    "\n",
    "# CIFAR10\n",
    "file = 'CIFAR10_epochs100_lr0.0002_beta1.0_type_VGG_classifier.pth'\n",
    "model = cc.vgg13(in_channels=3, num_classes=10)\n",
    "model.load_state_dict(torch.load(folder + file))\n",
    "\n",
    "model.cpu()\n",
    "torch.save(model, 'SavedModels/other/gan/' + 'CIFAR10' + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import OE\n",
    "trained using https://github.com/hendrycks/outlier-exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils.hendrycks as oe\n",
    "import utils.dataloaders as dl\n",
    "\n",
    "\n",
    "folder = 'SavedModels/other/outlier-exposure/'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# MNIST\n",
    "file = '../outlier-exposure/MNIST/snapshots/oe_scratch/oe_scratch_epoch_99.pt'\n",
    "\n",
    "model = oe.MNIST_ConvNet()\n",
    "model.load_state_dict(torch.load(file, map_location = device))\n",
    "model.cpu()\n",
    "torch.save(model, folder + 'hendrycks_MNIST' + '.pth')\n",
    "\n",
    "\n",
    "# FMNIST\n",
    "file = '../outlier-exposure/FMNIST/snapshots/oe_scratch/oe_scratch_epoch_99.pt'\n",
    "\n",
    "#model = oe.WideResNet(40, 10, channels=1, dataset='FMNIST')\n",
    "model = oe.ResNet18(num_of_channels=1, num_classes=10, dataset='FMNIST')\n",
    "model.load_state_dict(torch.load(file, map_location = device))\n",
    "model.cpu()\n",
    "torch.save(model, folder + 'hendrycks_FMNIST' + '.pth')\n",
    "\n",
    "\n",
    "# SVHN\n",
    "file = '../outlier-exposure/SVHN/snapshots/oe_scratch/wrn_oe_scratch_epoch_99.pt'\n",
    "\n",
    "#model = wrn.WideResNet(16, 10, 4, 0.4, dataset='SVHN')\n",
    "model = oe.ResNet18(num_of_channels=3, num_classes=10, dataset='SVHN')\n",
    "model.load_state_dict(torch.load(file, map_location = device))\n",
    "model.cpu()\n",
    "torch.save(model, folder + 'hendrycks_SVHN' + '.pth')\n",
    "\n",
    "\n",
    "# CIFAR10\n",
    "file = '../outlier-exposure/CIFAR/snapshots/oe_scratch/cifar10_resnet_oe_scratch_epoch_99.pt'\n",
    "\n",
    "#model = wrn.WideResNet(40, 10, 2, 0.3)\n",
    "model = oe.ResNet18(num_of_channels=3, num_classes=10, dataset='CIFAR10')\n",
    "model.load_state_dict(torch.load(file, map_location = device))\n",
    "model.cpu()\n",
    "torch.save(model, folder + 'hendrycks_CIFAR10' + '.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate [ODIN](https://arxiv.org/abs/1706.02690)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import model_params as params\n",
    "import utils.odin as odin\n",
    "\n",
    "import model_paths\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "out_seeds = True\n",
    "\n",
    "datasets = ['MNIST', 'FMNIST', 'SVHN', 'CIFAR10']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    model_params = params.params_dict[dataset](augm_flag=True)\n",
    "    path = model_paths.model_dict[dataset]().file_dict['Base']\n",
    "\n",
    "    model_params = params.params_dict[dataset]()\n",
    "\n",
    "    base_model = torch.load(path).to(device)\n",
    "    ODIN_model, _, _ = odin.grid_search_variables(base_model.to(device), model_params, \n",
    "                                                  device, out_seeds=out_seeds)\n",
    "\n",
    "    torch.save(ODIN_model.cpu(), 'SavedModels/other/odin/' + dataset + '_ODIN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate [Maha](https://arxiv.org/abs/1807.03888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import utils.dataloaders as dl\n",
    "\n",
    "import utils.single_maha as maha\n",
    "\n",
    "import model_params as params\n",
    "import model_paths\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "datasets = ['MNIST', 'FMNIST', 'SVHN', 'CIFAR10']\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    model_params = params.params_dict[dataset](augm_flag=True)\n",
    "    path = model_paths.model_dict[dataset]().file_dict['Base']\n",
    "\n",
    "    pretrained = torch.load(path).state_dict()\n",
    "\n",
    "    if dataset=='MNIST':\n",
    "        model = maha.LeNetMadry()\n",
    "    elif dataset=='FMNIST':\n",
    "        model = maha.ResNet18(1, 10)\n",
    "    elif dataset in ['SVHN', 'CIFAR10']:\n",
    "        model = maha.ResNet18(3, 10)\n",
    "\n",
    "    model.load_state_dict(pretrained)\n",
    "\n",
    "    maha_model = maha.Mahalanobis(model.to(device), model_params, device)\n",
    "    final_model = maha.ModelODIN(maha_model, model_params, device)\n",
    "\n",
    "    torch.save(final_model.cpu(), 'SavedModels/other/single_mahalanobis/' + dataset + '.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
